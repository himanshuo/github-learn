Main Memory - ch7
==================
### Background
Program is brought from disk into memory and placed within a process for it to be run.

CPU can only access main memory and registers. To access disk, CPU has to indirectly run instructions to put disk in main memory or registers.

Memory unit sees everything as a stream. The 2 things that are on this stream are  
  * read requests (contains address to read)
  * write requests (contain address to write to and data to write)

Register access is usually just 1 clock cycle. Main memory is much slower. This can lead to a **stall** where the CPU simply delays executing instructions.

Cache sits between main memory and CPU registers. It serves to make it so that stall time is less.

Protection of memory is required to ensure correct operation

### Base and Limit Registers
The logical address space is made up of **base registers** and **limit registers**. CPU checks every memory access made in user mode to make sure that the address is between the bast and limit for that user.
  * base register - minimum memory address user can access (closer to 0)
  * limit register - maximum memory address user can access (closer to max memory address possible)

![](main_memory-images/7b87ef1e5bab906412d1c588973ade50.png)


![](main_memory-images/15ba22bf118465ce9fc3b6228197fd6d.png)
  * shows how hardware addresses are protected using the base and limit registers  


### Address Binding
input queue - programs that are on disk and are ready to be brought on disk are put into the input queue
  * if there is no input queue, then the program must be loaded into address 0000
  * it is inconvenient to have first user process physical address always be 0000

Addresses can represented in different ways at different stages of a programs life
  * source addresses are usually symbolic
  * *compiled code addresses bind to relocatable addresses*
    * eg. 14 bytes from start of module
    * this can happen in 3 diff stages - compile time, load time, and execution time
  * *linker or loader will bind relocatable addresses to absolute addresses*
  * each binding maps one address space to another


The compiled code addresses are bound to relocatable addresses at three different stages
  * **compile time**
    * if memory location is known at compile time, then **absolute code** is generated.
  * **load time**
    * if memory location not known at compile time, then must generate **relocatable code**.
  * **execution time**
    * if the process can be moved from one memory segment to another during its execution, then binding is delayed until run time
    * this is where the base and limit registers come in play.

### There are multiple steps that occur when processing a User Program
![](main_memory-images/5535508b0cd1f16746c7728ec0b20d6f.png)

### Logical vs. Physical Address Space
**logical addresses spaces are bound to physical address spaces**

logical address - generated by CPU. Also called virtual address. The set of all logical addresses generated by a program is called the *logical address space*

physical address - address seen by the memory unit. This is the actual spot in memory where your data is stored. The set of all physical addresses generated by a program is called the *physical address space*.

Compile-time and load-time address binding schemes do not distinguish between logical and physical addresses. Execution-time addressing binding schemes see logical and physical addresses differently.  


### memory-management unit (MMU)
MMU is the hardware device that maps virtual to physical addresses at runtime.

There are many ways(or schemes) to do the mapping.

User program deals with logical addresses only and never sees the real physical addresses
  * execution time binding occurs when reference is made to location in memory

![](main_memory-images/fa78ab88afee1d7d3ca1db2c9cbd089f.png)
  * A sample simple scheme uses a relocation register which just adds a base value to address
    * physical memory addr = base register + virtual memory addr


A given function is not loaded until it is called. This allows for better memory space utilization because unused functions are never loaded.
  * for this to work, all routines must be kept on disk in a relocatable load format
  * this is especially useful when you have large amounts of code that need to handle infrequently occurring cases. Those infrequent functions don't remain in memory for long
  * another good thing about this is that it does not require special OS support

### Dynamic Linking
**static linking** - system libraries and program code are combined by the loader into the binary program image

**dynamic linking** - linking postponed until execution time
  * **stub** - a small piece of code is used to locate the correct function from memory
    * stub replaces itself with address of the correct function and executes it

OS must check whether the function you are trying to link is in the process's memory address. If it is not, then the OS adds it to the process's address space.

Dynamic linking is especially useful for libraries


### Swapping
A process can be swapped temporarily out of memory to a backing store and then brought back into memory for continued execution.
  * doing this allows for **total physical memory space of processes to exceed physical memory**. This occurs because you can just switch processes in and out of memory

**Backing Store** - fast disk that is large enough to hold copies of all memory images for all users. It must provide direct access to these memory images


**Roll out,roll in** - a type of swapping that is used for priority-based scheduling algorithms. Lower priority process is swapped out so higher priority process can be loaded and executed.

##### swapping is slow

The slow part of swap time is the transfer time. The transfer time is the time it takes to transfer the process between memory and the backing store.

##### swapping in and out

ready queue - queue of ready-to-run processes which have memory images on disk. You can remove these from disk and run them.

The swapped process may not swap back in to the same physical addresses, however, the virtual address will remain the same.

![](main_memory-images/7aaf907086413177a90cc0e778074128.png)
  * this image shows swapping

##### context switch time when swapping
if the next process to be put on CPU is not in memory, then you need to swap out a process and swap in a the target process

The context switch time can be very high

##### swapping when there is IO  
cant swap if a process is pending IO. If you did then the wrong process would get the IO

A way to get around this problem is to transfer IO to kernel space and then to IO device. The kernel would therefore alert the user process that IO has come in.
  * called *double buffering*

### Fixed/Static Partitioning
**Fixed/static partitioning** is when you divide memory into several fixed-sized partitions.
  * Each partition may contain exactly one process.
  * This is still a **multiple-partition method** because you have multiple partitions.
  * When a partition is free, a process is selected from the input queue and is loaded into the free partition.
  * When the process terminates, the partition becomes available for another process.
  * The OS keeps a table indicating which parts of memory are available and which are occupied.


### Contiguous Memory Allocation
Main memory must support both OS and user processes

There is a limited amount of memory so you have to allocate it efficiently. Contiguous Memory is one early method to do this efficiently.

Contiguous memory divides the memory into 2 partitions
  * memory for the OS is held in low memory addresses. This is also where interrupt vector table is held
  * user processes are held in high memory address.  
  * each process is contained in a single contiguous section of memory


Relocation registers are used to protect user processes from each other and from changing OS code and data.
  * base register contains value of smallest physical address
  * limit register contains range of logical(virtual) addresses
    * each logical address must be less than the limit register
  * MMU maps logical address **dynamically**
  * Because of the base register separating the OS and user code, and because the MMU maps the virtual memory dynamically, the kernel code can be changed around. Kernel code size thus changes. This feature is said to make the kernel code **transient**


### Multiple Partition Allocation
The amount of multiprogramming you can do is limited by the number of partitions you can have. Thus there is **variable-partition** sizes for efficiency. Each partition has the size that the appropriate process needs.

**hole** - block of available memory. holds of various sizes are scattered throughout memory.
  * When a process arrives, it is allocated to a hole that is large enough
  * When the process exits, the partition is freed and combined with any adjacent free partitions.
  * **coalescing**  - combining newly freed memory with adjacent free partitions


![](main_memory-images/7bea52c6654512f8c9f3f793e7cdf854.png)
  * process 8 exits and creates a hole
  * process 5 arrives and is allocated some space

For this to work, OS must store information about
  * allocated partitions
  * free partitions (holes)

##### Dynamic Storage-Allocation Problem / Solution
Say a process allocation request comes in where the process has size n. You have a list of free holes, but which one do you choose?

Solutions  
* first-fit - allocate the *first* hole that is big enough
  * fastest
* best-fit - allocate the *smallest* hole that is big enough. This requires searching the entire list, unless the list is ordered by size
  * most storage efficient
  * if ordered list, then also decently fast
* worst-fit - allocate the *largest* hole. Requires searching entire list.


### Fragmentation
external fragmentation - allocated memory is stored in non-contiguous locations

internal fragmentation - allocated memory may be slightly larger than requested memory. This happens because you have bookkeeping information about the allocated memory. This size difference is memory internal to a partition but is not being used.

50-percent rule - analysis done on first fit dynamic storage allocation reveals that half of all blocks are lost to fragmentation. This then yields that 1/3 of all blocks may be unusable.


compaction - shuffle memory contents to place all free memory together in one large block
  * this is a way to reduce external fragmentation
  * Compaction is possible only if relocation is dynamic and is done at execution time

Backing store has same fragmentation problems

### Segmentation
Segmentation is a memory management scheme that supports user view of memory

A problem is a collection of segments. A segment can be any of   
  * main program
  * function
  * object
  * local variables, global variables
  * stack
  * arrays
  * symbol table
  * common block

![](main_memory-images/558ee2dd20ae3c5ac5af87b2537d20f3.png)
  * this is how user sees a program
  * there is a logical address for each of these things

![](main_memory-images/5a331b79d58dd0143c873b984e65ee46.png)
  * this shows how the segments could be laid out in physical memory

##### Segmentation architecture
logical address consists of a two tuple: <segment number, offset>

segment table - maps 2d physical addresses. each table entry has
  * base - starting physical address segments reside in memory
  * limit - length of segment

Segment-table base register (STBR) - points to segment table's location in memory

Segment-table length register(STLR) - indicates number of segments used by a program

Note: segment number must be *less than* STLR


Segmentation architecture has built in protection
  * each segment in segment table has a validation bit
  * each segment has read/write/execute privileges

Segments vary in length


![](main_memory-images/a81f982cf320b0f146f5a14bcab590f4.png)
  * CPU provides logical address
  * logical addresses has segment number(s) and offset(d)
  * the segment table is found at (base, base+limit)
  * go down s spots in segment table to find correct segment entry
    * verify that s is less than the limit
  * physical address = lookup(s) + d  

### Paging
Segmentation allows the physical address space of a process to be non-contiguous. Paging is another memory-management scheme that does the same. However, paging avoids external fragmentation and the need for compaction, whereas segmentation does not.

Thus the benefits of paging are
  * all the benefits of segmentation (physical space of a process can be non-contiguous)
  * no external fragmentation
  * no varying sized memory chunks and thus no need for compaction

##### Basic Method
Divide physical memory into fixed-size blocks called **frames**

Divide logical memory into blocks of same size called **pages**

Keep track of all free frames

To run a program of size N pages, you need to find N free frames and then load the program

A **page table** is used to translate logical to physical addresses.

The backing store is split into pages.

You still have internal fragmentation.

##### Address Translation Scheme for Paging
![](main_memory-images/a30d70f61695a9a0211f107789080750.png)
  * page number p is an index into the page table. The page table contains base address of each page in physical memory.
  * page offset d is combined with the base address to define the physical memory address that is sent to the memory unit to look for.
  * thus, physical address = page_table_lookup(p)+d
  * the logical address space has length 2^m, thus you can have 2^m pages. Each page has length 2^n.

![](main_memory-images/106c8be8645c5a0bf78ea356cbd5d3a6.png)
  * physical address = combine the page table lookup of p with the same offset.

![](main_memory-images/fef7a78a8c35ddc21a484032d03b65ce.png)
  * logically, you see pages next to each other.  
  * the page table can then map them to various spots in the physical memory
  * the physical memory is thus segmented

![](main_memory-images/d0156d008420ad0b00517d621adbde64.png)
  * the logical address has 16 bytes, page size of 4, thus 4 pages in logical address space.
  * 4 entries in page table since there are 4 pages in the logical address space
  * *offset (d) can be 0-3, thus n=2*
  * frame size is always equal to page size
  * physical memory has 32 bytes, and frame size of 4, thus there are 8 frames
  * each page table entry is >= 3 bytes because there are 8 frames to represent.
    * The > part comes in because each page table entry also protection and validation bits.
  * in this case, the logical addresses size is 4 (m=4). Thus there are m-n=4-2=2 bits for the page table. Thus you can only have 4 page table entries

##### Calculating Internal Fragmentation
Given:  

* page size = 2048 bytes
* process size = 72,766 bytes

You will have 72766 = 35 pages + 1086. Thus you have 1086 bytes left over

Internal Fragmentation = 2048 - 1086 = 962 bytes of internal fragmentation

##### Fragmentation cases
Worst Case Fragmentation:  `1 frame - 1 byte`

Average Case Fragmentation: `1/2 frame size`

Thus it may seem like small frame sizes are good, since you will not have as much fragmentation. However, each page table entry takes memory to track, so having too small of a frame size won't work.


##### Key Ideas to note in the Paging model of Segmentation
A process view and physical view are very different

The implementation itself makes it so that a process can only access its own memory

### Free Frames
You have a free frames list which is basically a linked list between free frames. You can use the list to allocate new memory.

There are numerous schemes for how to allocate memory using the free frames.


### Implementing the Page Table
The page table is in main memory.

A Page-table base register (PTBR) points to the page table. A Page-table length register (PTLR) indicates the size of the page table.

If you want to access memory, you have to first look into the page table to determine which frame to look for, and then use that generated physical address to look into main memory again.

Thus, you have to make 2 main memory lookups to find anything in memory. This is slow.

To speed things up, you can use a hardware cache called a translation look-aside buffer (TLB). A TLB simply stores recent things that you have looked up in the page table. Then, in the future, when you need to look for something in the page table, you simply look at the TLB. TLB is simply a cache for the page table.  


Thus the flow of generating the physical address from a logical address looked like the picture below.

![](main_memory-images/1b3bc795669ea160f2bdabd415a553c4.png)

### Memory Protection
A protection bit is given to each frame to indicate whether it is read, write, execute abilities.

There is also a valid-invalid bit attached to each entry in the page table.
  * valid = associated page is in the process's logical address space and is thus a legal page
  * invalid = page is not in the process's logical address space

Any violations of any of the memory protection bits leads to a trap, that leads to kernel's trap handler being run.


##### Shared Pages
You can have shared pages which simply means that there is a single copy of read-only (reentrant) code that is shared among processes.

This is similar to the idea of multiple threads sharing the same process space.

Shared pages are useful for interprocess communication.
##### private code and data
along with the shared pages, each process also has its own separate copy of code and data. The pages for the private code and data can be anywhere in its logical address space.



![](main_memory-images/ca5333fc1796e9fe7efbbe648d1afe57.png)
  * each process has its own logical address space
  * each process has its own page table
  * the shared data is only store once in the physical memory. Each process knows where to access it since the page table points to it (3,4,6).
  * each process also has its own private data


### Ways to make Page Table Manageable
The Page Table can get too big too quickly. Thus there are numerous ways to make the page table much smaller.
  * Hierarchical Paging
  * Hashed Page Tables
  * Inverted Page Tables

##### Hierarchical Paging
Hierarchical Paging is breaking up the logical address space into multiple page tables

For example, you can have a two-level page table. This requires making a page for the page tables.

![](main_memory-images/f9b0815db86283fa46d837f0f98eddb9.png)
  * two-level page table
  * the logical address points to the outer page table
  * the outer page table then points to the page table
  * the page table then points to memory

*forward-mapped page table* - a two level page table

*clustered page table* - a multilevel page table ( > 2 levels)

**Example: forward-mapped page table**

logical address on a 32 bit machine with 1K page size is divided into (2^10=1K) 10 bits of page offset and 22 bits of page numbers.

the page numbers is further divided because there are two levels of page tables. The second level is 10 bits because it is rightmost. The first level is 12 bits.

![](main_memory-images/bffc62a4a2826bb62dcd4e624b51b6b0.png)
  * p1 is an index into the outer page table
  * p2 is displacement within the page of the inner page table

![](main_memory-images/ee2283c6e05f5565924f7cee0636070d.png)
  * this is how the a two level page table is used to determine physical address
  * p1 is used to get a page table to look at from outer page table
  * p2 is used to know how far into page table to look at to get the resulting physical frame
  * d is used to know how far into the frame to go to get the desired data

  **Example: clustered page table with 64 bit address space**

  logical address on a 64 bit machine with 1K page size is divided into (2^10=1K) 10 bits of page offset and 22 bits of page numbers.

  the page numbers is further divided because there are two levels of page tables. The second level is 10 bits because it is rightmost. The first level is 12 bits.

  ![](main_memory-images/bffc62a4a2826bb62dcd4e624b51b6b0.png)
    * p1 is an index into the outer page table
    * p2 is displacement within the page of the inner page table

  ![](main_memory-images/ee2283c6e05f5565924f7cee0636070d.png)
    * this is how the a two level page table is used to determine physical address
    * p1 is used to get a page table to look at from outer page table
    * p2 is used to know how far into page table to look at to get the resulting physical frame
    * d is used to know how far into the frame to go to get the desired data



##### Hashed Page Tables
hashed page table

clustered page tables

sparse

##### Inverted Page Tables


### Summary
hardware support -
performance -
fragmentation -
relocation -
swapping -
sharing -
protection
